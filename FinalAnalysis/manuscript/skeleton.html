<!DOCTYPE html>
<html lang="en-US" xml:lang="en-US">
<head>
<meta http-equiv="Content-Type" ontent="text/html; charset=UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Peak power from maximal vertical jump height determines radial bone strength better than hand grip strength in healthy individuals</title>
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,400i,900,900i" type="text/css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css" type="text/css" />

<style>
body {
    background-color:#fff;
    font-family: "Lato", sans-serif;
    overflow: auto;
    -webkit-overflow-scrolling: touch;
    max-width: 75%;
    margin: auto;
}

sub,sup {
font-size: 75%;
line-height: 0;
position: relative;
vertical-align: baseline
}

sub{
bottom: -0.25em
}

sup{
top: -0.5em
}

img {
    display: block;
    margin-left: auto;
    margin-right: auto;
    border: 1px solid #ddd;
    padding: 5px;
    max-width: 90%;
}

h1 { 
    display: block;
    font-size: 180%;
    margin-bottom: 0;
    margin-left: 0;
    margin-right: 0;
    font-weight: bold;
}

h2 { 
    display: block;
    font-size: 130%;
    color: #000; 
    margin-top: 1em;
    padding-top: 20px;
    margin-bottom: 0.40em;
    margin-left: 0;
    margin-right: 0;
    font-weight: bold;
}

h3 { 
    display: block;
    color: #818181;
    font-size: 110%;
    margin: 0 0 0 0;
    font-style: italic;
}

hr {
    border: 0;
    width: 80%;
    color: #818181;
    background-color: #818181;
    height: 1px;
}

p.caption { 
    text-align: center;
    display: block;
    font-size: 85%;
}

p.media { 
    text-align: center;
    display: block;
}

.abstract {
    background-color: #f2f2f2;
    border-left: 5px solid #818181;
    padding: 5px 20px 5px 20px;
}

.sidenav {
    height: 100%;
    width: 200px;
    position: fixed;
    z-index: 1;
    height: 100%;
    overflow: hidden;
    background-color: #fff;
    padding-top: 0px;
    border-right: 1px solid #818181;
}

.sidenav a {
    padding: 6px 8px 6px 16px;
    text-decoration: none;
    font-size: 120%;
    color: #818181;
    display: block;
}

.sidenav a:hover {
    color: #f1f1f1;
}
-->
.main {
    margin-left: 200px; /* Same as the width of the sidenav */
    padding: 0px 10px;
    height: 100%;
    overflow: visible;
    -webkit-overflow-scrolling: touch;
}


/* On screens that are less than 700px wide, make the sidebar into a topbar */
@media screen and (max-width: 700px) {
  .sidenav {
    width: 100%;
    height: auto;
    position: relative;
    border-right: none;
  }
  .sidenav a {float: left;}
  .main {margin-left: 0;}
}

/* On screens that are less than 400px, display the bar vertically, instead of horizontally */
@media screen and (max-width: 400px) {
  .sidenav a {
    text-align: center;
    float: none;
    border-right: none;
  }
}

.hangingindent {
  padding-left: 22px ;
  text-indent: -22px ;
}
</style>

</head>
<body>

<div class="sidenav">
  <a href="#abstract">Abstract</a>
  <a href="#introduction">Introduction</a>
  <a href="#methods">Methods</a>
  <a href="#results">Results</a>
  <a href="#discussion">Discussion</a>
  <a href="#additional-information">Additional Information</a>
  <a href="#references">References</a>
</div>

<div class="main">


<div class="fluid-row" id="header">




<h1 class="title">The Nature of Our Literature: An Observational Study of the Positive Result Rate and Reporting Practices in Kinesiology</h1>
<br>
Some Name<sup>1</sup>, 
Same Name<sup>1</sup>, 
Another Nombre<sup>2</sup>, 

      

<p class="date"><span class="glyphicon glyphicon-calendar"></span>Last Updated: 2021-07-17</p>

</div>


<!-- <p style="text-align:center;"><i>Commmunications in Kinesiology</i></p> -->
<p><em>Affiliations</em>
<br> 
1 - Fake University <br>
2 - Fake Place <br>
</p>
<p>
  <strong>Corresponding Author:</strong> 
  <br> 
  S. Name 
  <br>
  <a href="mailto:s.name@fake.edu" class="email">s.name@fake.edu</a>
</p>
  <br>


<div id="abstract" class="section level2">
<h2>Abstract</h2>
<!-- background-color: #f2f2f2;
    border-left: 5px solid #818181;
    padding: 5px 20px 5px 20px;-->
<!-- border:2px; border-style:solid; border-color:#BEE59E; padding: 1em; background-color:gray-->
<!-- border-left: 5px solid #818181;
    padding: 5px 20px 5px 20px;-->
<p style="
    background-color:rgba(207, 250, 209, 0.75);
    border-left: 5px solid #818181;
    padding: 5px 20px 5px 20px;
    ">
Scientists rely upon an accurate scientific literature in order to build and test new theories about the natural world. In the past decade, observational studies of the scientific literature have indicated that numerous questionable research practices and poor reporting practices may be hindering scientific progress. In particular, 3 recent have indicated a implausibly high rate of studies with positive (i.e., hypothesis confirming) results. In Sports Medicine, a field closely related to Kinesiology, studies that tested a hypothesis indicated support for their primary hypothesis ~70% of the time. However, a study of journals that cover the entire field of Kinesiology has yet to be completed, and the quality of other reporting practices, such as clinical trial registration, has not been evaluated. Therefore, in this study we will retrospectively evaluate 300 original research articles from the flagship journals of America (Medicine and Science in Sport and Exercise), Europe (European Journal of Sport Science), and Australia (Journal of Science and Medicine in Sport).
</p>
</div>
  


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Scientists and knowledge-users who make decisions based on scientific evidence rely on the published literature to be reported transparently and to be an accurate representation of the research that scientists conduct. The ability to replicate scientific findings is vital to establish the credibility of scientific claims and to allow research to progress <span class="citation">(Nosek &amp; Errington, 2019)</span>. A large-scale collaborative effort estimated the replicability of findings in psychological science and found that most replication effects are smaller than originally reported <span class="citation">Collaboration (2015)</span>. Whilst this is a complex issue, questionable research practices (QRPs) and publication bias explain at least some of the differences between the original and replication effect sizes <span class="citation">(Head et al., 2015; John et al., 2012; Simmons et al., 2011)</span>. Alongside psychology <span class="citation">Collaboration (2015)</span>, other fields have struggled to replicate or reproduce findings, including neuroscience <span class="citation">(Boekel et al., 2015; Kharabian Masouleh et al., 2019; Turner et al., 2018)</span>, cancer biology <span class="citation">(Nosek &amp; Errington, 2017)</span>, human genetics <span class="citation">(“Replicating Genotype–Phenotype Associations,” 2007)</span> and pharmacology <span class="citation">(Prinz et al., 2011)</span>. This type of systematic replication and evaluation of previously published results has not yet been attempted in kinesiology (alternatively known as sport and exercise science). However, considering the similarities (e.g,. the study of human behaviour) and overlap (e.g. sport and exercise psychology) between psychology and kinesiology, we have reason to believe it may suffer from the same QRPs. Replication appears to be rare in kinesiology, which is perhaps surprising considering that kinesiology has been the focus of significant critique due to overly optimistic inferences <span class="citation">(Sainani et al., 2019)</span> and a history of underpowered studies <span class="citation">(Abt et al., 2020)</span>. Furthermore, a lack of sample size estimation <span class="citation">(Abt et al., 2020)</span>, misuse of p-values and statistical significance testing, limited collaboration with statisticians <span class="citation">(Sainani et al., 2020)</span>, minimal or arbitrary use of effect sizes <span class="citation">(Caldwell &amp; Vigotsky, 2020)</span>, and other reporting issues <span class="citation">(D. N. Borg, Lohse, et al., 2020)</span> appear to be commonplace.</p>
<p>In the past few years, a community of researchers in kinesiology have been advocating for and adopting open and replicable research practices <span class="citation">(D. N. Borg, Bon, et al., 2020; D. N. Borg, Lohse, et al., 2020; A. R. Caldwell et al., 2020,Vigotsky_Nuckols_Heathers_Krieger_Schoenfeld_Steele_2020; Sainani et al., 2020, p. @Caldwell_Vigotsky_2020)</span>. Some journals in the field have started to adopt the Registered Report format for manuscripts which is commendable (see \url{www.cos.io/rr for a list of participating journals). However, such practices include openly sharing data and code, pre-registration, and using the registered reports format (for a primer, see <span class="citation">A. R. Caldwell et al. (2020)</span> for details). Some of the issues that motivated the open science movement in psychology and other fields <span class="citation">Munafò et al. (2017)</span> are comparatively unexplored in kinesiology, and in addition currently, the number of kinesiology researchers adopting open research practices is largely unknown. There is some indication that both pre-registration and sharing of data is uncommon <span class="citation">(D. N. Borg, Lohse, et al., 2020; Tamminen &amp; Poucher, 2018)</span> and flagship journals of our field (e.g., Medicine &amp; Science in Sport &amp; Exercise, European Journal of Sport Science) do not include a statement encouraging data sharing in the author guidelines (Oct 2020). Evaluating a recent sample of the kinesiology literature for such practices may help draw attention to these potential issues.</p>
<p>Another issue that warrants consideration is the positive result rate (the rate at which a published study finds support for its hypothesis) of published kinesiology studies. Recently, <span class="citation">Büttner et al. (2020)</span> estimated the positive result rate in three high ranking sports journals and one high ranking sports physiotherapy journal. In line with previous research in other scientific disciplines <span class="citation">(Fanelli, 2010; Scheel et al., 2020)</span>, the positive result rate exceeded 80%. What are the mechanisms for the suspiciously high positive result rates in the scientific literature? Given the assumption of a completely unbiased literature, such a high positive result rate could only occur if both statistical power and the proportion of true hypotheses that researchers have chosen to test is consistently high <span class="citation">Scheel et al. (2020)</span>. The more plausible explanation perhaps, corroborated in previous work <span class="citation">(John et al., 2012; Simmons et al., 2011)</span>, is that the literature is distorted by undisclosed flexibility in analysis and other QRPs, and the incentive to publish positive results. Registered reports are specifically designed to help mitigate these issues <span class="citation">Chambers et al. (2015)</span>. Therefore, <span class="citation">Scheel et al. (2020)</span> assessed the positive result rate in research articles published using the traditional format in comparison to registered reports in a sample of the psychology literature. The positive result rate was an implausibly high 96% for traditional articles and a significantly lower 46% for registered reports. The increased methodological rigour inherent to the registered report format has clearly led to an increase in the reporting of null findings in the psychological literature.</p>
<p>The equivalent findings regarding standard and registered reports have not been reported for kinesiology, and simply would not be possible given the current literature; unlike psychological science <span class="citation">Scheel et al. (2020)</span>, and to our knowledge, kinesiology has not accumulated more than 70 RRs to evaluate against traditional publication formats. Nevertheless, the adoption of registered reports in kinesiology is progressing slowly. One reason for this may be a lack of awareness regarding the replication crisis and movement towards more rigorous and transparent research practices. However, the slow adoption of registered reports could also be due to a lack of concern about the kinesiology literature given the limited evidence that a problem exists. Therefore, the primary aim of this study is to assess the positive result rate of reported hypotheses in the recent kinesiology literature, using society-affiliated flagship journals from the field. Considering the majority of scientific disciplines documented by <span class="citation">Fanelli (2009)</span> had a positive rate of 80%, we hypothesize that the $&gt;$80% of the published studies in kinesiology will report positive results (i.e, support for the hypothesis) for their first stated hypothesis. Our secondary aims are to assess a number of related research practices, including whether the kinesiology literature includes replications of previous effects, the detail of statistical reporting and adoption of other transparent reporting practices. </p>
</div>
<div id="methods" class="section level1">
<h1>Methods</h1>
<div id="sample" class="section level2">
<h2>Sample</h2>
<p>Research articles will be sampled from three flagship kinesiology journals: Medicine and Science in Sport and Exercise (MSSE), the European Journal of Sport Science (EJSS) and the Journal of Science and Medicine in Sport (JSAMS), which represent three major kinesiology societies of North America (American College of Sports Medicine), Europe (European College of Sport Science) and Australia (Sports Medicine Australia), respectively. We selected three major societies and their official flagship journals because we believe they will represent a diverse selection of research in kinesiology and provide insights into the practices of the field as a whole. In addition, we chose to focus on these three journals rather than a random sample of the entire literature because these journals should represent the best research in the field (compared to any published article which could be sampled from a predatory publisher). We plan to select 100 original research articles per journal, 300 in total, excluding study protocols, methodological tutorials/reports, opinions, commentaries, perspectives, conference proceedings, narrative reviews, systematic reviews and meta-analyses. We will also exclude research articles if they have been retracted or contain insufficient information to reach coding decisions. To sample a recent selection of the literature, research articles will be sampled consecutively backwards from December 31, 2019, by the data analyst (ARC).</p>
</div>
<div id="data-extraction" class="section level2">
<h2>Data Extraction</h2>
<p>We have identified nine coders who will be responsible for data extraction. Coders will undergo standardized training that has been designed based on the queries raised and clarification required during pilot testing (see later section). These nine coders will form three teams of three, and each team will be randomly allocated the research articles from one journal (MSSE, EJSS, or JSAMS). All coders will extract data independently and enter this directly into a Qualtrics survey. The Qualtrics survey was refined after pilot testing and a copy is available at  . Each team will be coordinated by a team leader trained at a doctoral level in a kinesiology discipline (RT, VY and JW). Once independent coding is complete, interrater reliability will be assessed using Fleiss’s Kappa, and the number of major disagreements (support vs. no support for the hypothesis) will be reported. Team leaders will be responsible for resolving all conflicts (any instance where there is not agreement between all group members) within their team through group review of the item and group discussion. Where conflicts cannot be resolved (and revised if necessary) using this process, the team leader will consult the other two team leaders. If the other two team leaders do not fully endorse the original team leader’s decision, the majority decision from the original coding will be accepted. All data (original coder responses and summary decisions) will be available after the completion of this study’s Open Science Framework repository.</p>
</div>
<div id="measures-and-coding-procedure" class="section level2">
<h2>Measures and Coding Procedure</h2>
<p>All articles will be categorized as basic physiology (animal and cell physiology), applied exercise physiology (human), environmental physiology (heat, cold, and altitude), clinical research, biomechanics, motor learning/control/behaviour, epidemiology, sport/exercise psychology, sport performance, or other (the category that best describes the article). Research articles that do not include explicit statements that a hypothesis was tested will not be included in the analysis of the positive result rate. However, all articles (i.e., 300) will be included in analysis related to replication status, statistical reporting and other reporting practices, as described in the following sections.</p>
</div>
<div id="support-for-a-hypothesis-in-the-kinesiology-literature" class="section level2">
<h2>Support for a Hypothesis in the Kinesiology Literature</h2>
<p>From the 300 articles, we expect that approximately 60% will include explicit statements that a hypothesis was tested as part of the study (e.g., “We hypothesized that…”) <span class="citation">(Büttner et al., 2020)</span>. Therefore, we expect to extract data on the positive results rate from approximately 180 research articles. The main dependent variable is whether the first stated hypothesis was supported or not, as reported by the authors. We plan to closely follow the coding procedure used by <span class="citation">Fanelli (2010)</span> and <span class="citation">Scheel et al. (2020)</span>, which is described as follows: By examining the abstract and/or full text, it will be determined whether the authors of each paper had concluded to have found a positive (full or partial) or negative (null or negative) support. If more than one hypothesis was being tested, only the first one to appear in the text will be considered. The coding of support for the hypothesis will be based on the author’s description of their results. In line with previous work <span class="citation">(Büttner et al., 2020; Scheel et al., 2020)</span>, we will also code a hypothesis as having received “support,” “partial support,” “no support” or “unclear or not stated”. We have added this fourth option after pilot indicated that some authors failed to state whether or not the study’s hypotheses were, or were not, supported in the discussion section of the manuscript. This will be re-coded into a binary “support” (full or partial) vs. “no support” variable, with “unclear or not stated” removed, for the main analysis. Coding disagreements between full and partial support will be deemed minor since they will not affect the results. Thus, only disagreements affecting the binary support/no support or the unclear classification will be treated as major and resolved through discussion. The language used to state a hypothesis and support for the first tested hypothesis will be included in the data extraction.</p>
</div>
<div id="replication-status" class="section level2">
<h2>Replication Status</h2>
<p>Coders will assess whether a study is a replication of a previously published one, as reported by the authors. Coders will search the full texts of all papers for the string ‘replic*’ and, for papers that contain it, indicate whether the coded hypothesis was a close replication with the goal to verify a previously published result <span class="citation">(Scheel et al., 2020)</span>. Internal replications (replication of a study within the same paper) will not be counted as replications.</p>
</div>
<div id="statistical-reporting" class="section level2">
<h2>Statistical Reporting</h2>
<p>Coders will assess whether authors included language related to statistical significance and if p-values were included in the results (relating to all analyses and not only the first hypothesis). If yes, coders will assess if the p-value was interpreted as significant and if the exact or relative p-value was reported (i.e., <span class="math inline">\(p=0.049\)</span> vs. <span class="math inline">\(p&lt;0.05\)</span>). If a relative p-value was reported, the level of the reported p-value (e.g., <span class="math inline">\(p&lt;0.05\)</span>, <span class="math inline">\(p&lt;0.01\)</span>) will be coded. Coders will also extract whether an effect size was reported, including, but not limited to: Cohen’s d, correlation coefficients, mean differences, and measures of model fit (e.g., coefficient of determination: <span class="math inline">\(R^2\)</span>). Finally, coders will assess whether the information on sample size is provided, and if provided, the total sample size (the number of participants included in the analyses, rather than the planned sample size) will be extracted. Finally, coders will assess whether any sample size justification (e.g. power analysis) was included in the manuscript.</p>
</div>
<div id="other-reporting-practices" class="section level2">
<h2>Other Reporting Practices</h2>
<p>Coders will assess whether the study is a clinical trial, according to the ICJME definition (). If yes, coders will assess if a clinical trial registration is reported in the manuscript. For all other types of studies, coders will assess whether studies have been pre-registered (as reported within the manuscript). Coders will assess if a manuscript provides a statement on data availability, and if yes, whether there is open access to the original data and/or code via a link or supplementary file. All additional measures we collect but have not described thus far will either be auxiliary variables to facilitate the coding process or earlier versions of the variables discussed above.</p>
</div>
<div id="pilot-testing" class="section level2">
<h2>Pilot Testing</h2>
<p>To ensure that our questionnaire for our raters accurately and consistently reflects the above-detailed information from relevant articles, we conducted pilot testing before submission of the Stage 1 manuscript. Fifteen original research articles published in 2018, five from each of our three chosen journals, were selected to be used for pilot testing. One team of naive coders (i.e., were not trained prior to coding) extracted all data from these articles and entered this into Qualtrics. Independent coding was checked for disagreements, and this was used to inform training procedures. Pilot aggregated data were generated, and further adjustments were made to refine the planned extraction and analysis process. A summary report of the pilot work can be found at . Overall, our pilot work indicated minimally acceptable agreement among the raters on the questions essential to our study such as whether a hypothesis was tested (<span class="math inline">\(\kappa\)</span>= 0.903; complete agreement = 14/15) and if the authors found support for this hypothesis (<span class="math inline">\(\kappa\)</span>= 0.586; complete agreement = 6/9). For all items with rater disagreement, at least two coders were in agreement on the rating. After the conclusion of pilot testing, a forum among the team was completed in order to appropriately adjust the questionnaire and refine future instructions/training for the coding teams in the full study. Prior to coding, all coding team members will undergo formal training and will be presented with example articles (not from the study sample) in order to improve consistency in the coding process.</p>
</div>
<div id="analysis-plan" class="section level2">
<h2>Analysis Plan</h2>
<p>We plan to estimate the rate at which kinesiology research finds support for the first tested hypothesis (as reported by the authors). Further, we plan to compare this to the majority of disciplines surveyed in <span class="citation">Fanelli (2010)</span> which reported a positive result rate in excess of 80% (16 of 20 disciplines). We find it unlikely that kinesiology would have a positive result rate lower than 80%, and believe that the actual rate is closer to the social sciences at approximately 85% <span class="citation">(Fanelli, 2010)</span>. Considering we have a good prior information, and a belief we want to test, we have opted to use a Bayesian analysis to test our hypothesis. Therefore, we plan to test our hypothesis that the positive result rate is greater than 80% using a generalized Bayesian regression model <span class="citation">(Bürkner, 2017)</span>. We assumed a prior of <span class="math inline">\(\beta(17,3)\)</span> on the intercept of the model (i.e., the rate of positive results). Evidence for our hypothesis will be reported as the posterior probability, <span class="math inline">\(pr(Intercept &gt; .8 | data)\)</span>, of our hypothesis and Bayes Factor (BF) the ratio of evidence for our hypothesis versus the null. We performed a Monte Carlo simulation assuming we obtained 150 studies which contained hypotheses from a population where 85% will contain a positive result for the first stated hypothesis. This simulation indicated that our model would have an 87% chance of being able to obtain some evidence (BF in favor of our hypothesis <span class="math inline">\(&gt;\)</span> 3) for our hypothesis. All other data will be summarized descriptively and as frequencies and proportions. A detailed summary of the planned hypothesis test and “power” analysis can be found at .</p>
</div>
<div id="greek" class="section level2">
<h2>Greek</h2>
<p>Many times greek letters/symbols need to be provided outside of math mode. So you may say <span class="math inline">\(\beta\)</span></p>
</div>
<div id="superscript" class="section level2">
<h2>Superscript</h2>
<p>You can give Superscript<sup>1</sup> or Subscript<sub>2</sub></p>
</div>
<div id="quotes-and-block-quotes" class="section level2">
<h2>Quotes and Block Quotes</h2>
<blockquote>
<p>This can easily be done</p>
<ul>
<li>ME</li>
</ul>
</blockquote>
</div>
<div id="links" class="section level2">
<h2>Links</h2>
<pre><code>A [linked phrase][id].</code></pre>
<p>At the bottom of the document:</p>
<pre><code>[id]: http://example.com/ &quot;Title&quot;</code></pre>
</div>
<div id="images" class="section level2">
<h2>Images</h2>
<pre><code>![alt text][id]</code></pre>
</div>
<div id="math" class="section level2">
<h2>Math</h2>
<p>Fortunately the math formulas do not differ too much for HTML and PDF documents. For inline math a single <code>$</code> is necessary while <code>$$</code> creates formula on its own line.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="results" class="section level1">
<h1>Results</h1>
<div id="confirmatory-results" class="section level2">
<h2>Confirmatory Results</h2>
<div class="figure">
<img src="figure1.png" alt="Figure 1. Posterior distributions from Bayesian model with 50\% and 95\% compatibility intervals " width="100%" />
<p class="caption">
Figure 1. Posterior distributions from Bayesian model with 50% and 95% compatibility intervals
</p>
</div>
</div>
<div id="exploratory-results" class="section level2">
<h2>Exploratory Results</h2>
<div id="statistics-reporting" class="section level3">
<h3>Statistics Reporting</h3>
</div>
<div id="other-important-reporting-practices" class="section level3">
<h3>Other Important Reporting Practices</h3>
</div>
<div id="breakdown-by-journal" class="section level3">
<h3>Breakdown by Journal</h3>
</div>
<div id="breakdown-by-discipline" class="section level3">
<h3>Breakdown by Discipline</h3>
</div>
<div id="analysis-of-rct-and-clinical-trials" class="section level3">
<h3>Analysis of RCT and Clinical Trials</h3>
</div>
</div>
</div>
<div id="discussion" class="section level1">
<h1>Discussion</h1>
<p>Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim. Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu. In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo. Nullam dictum felis eu pede mollis pretium. Integer tincidunt. Cras dapibus. Vivamus elementum semper nisi. Aenean vulputate eleifend tellus.</p>
<p>Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac, enim. Aliquam lorem ante, dapibus in, viverra quis, feugiat a, tellus. Phasellus viverra nulla ut metus varius laoreet. Quisque rutrum. Aenean imperdiet. Etiam ultricies nisi vel augue. Curabitur ullamcorper ultricies nisi. Nam eget dui. Etiam rhoncus. Maecenas tempus, tellus eget condimentum rhoncus, sem quam semper libero, sit amet adipiscing sem neque sed ipsum. Nam quam nunc, blandit vel, luctus pulvinar, hendrerit id, lorem. Maecenas nec odio et ante tincidunt tempus.</p>
<p>Donec vitae sapien ut libero venenatis faucibus. Nullam quis ante. Etiam sit amet orci eget eros faucibus tincidunt. Duis leo. Sed fringilla mauris sit amet nibh. Donec sodales sagittis magna. Sed consequat, leo eget bibendum sodales, augue velit cursus nunc, quis gravida magna mi a libero. Fusce vulputate eleifend sapien. Vestibulum purus quam, scelerisque ut, mollis sed, nonummy id, metus. Nullam accumsan lorem in dui. Cras ultricies mi eu turpis hendrerit fringilla. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; In ac dui quis mi consectetuer lacinia.</p>
<p>Nam pretium turpis et arcu. Duis arcu tortor, suscipit eget, imperdiet nec, imperdiet iaculis, ipsum. Sed aliquam ultrices mauris. Integer ante arcu, accumsan a, consectetuer eget, posuere ut, mauris. Praesent adipiscing. Phasellus ullamcorper ipsum rutrum nunc. Nunc nonummy metus. Vestibulum volutpat pretium libero. Cras id dui. Aenean ut eros et nisl sagittis vestibulum. Nullam nulla eros, ultricies sit amet, nonummy id, imperdiet feugiat, pede. Sed lectus. Donec mollis hendrerit risus. Phasellus nec sem in justo pellentesque facilisis. Etiam imperdiet imperdiet orci. Nunc nec neque. Phasellus leo dolor, tempus non, auctor et, hendrerit quis, nisi. Curabitur ligula sapien, tincidunt non, euismod vitae, posuere imperdiet, leo. Maecenas malesuada. Praesent congue erat at massa. Sed cursus turpis vitae tortor. Donec posuere vulputate arcu. Phasellus accumsan cursus velit. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Sed aliquam, nisi quis porttitor congue, elit erat euismod orci, ac</p>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>orem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim. Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu. In enim justo, rhoncus ut, imperdiet a, venenatis vitae, justo. Nullam dictum felis eu pede mollis pretium. Integer tincidunt. Cras dapibus. Vivamus elementum semper nisi. Aenean vulputate eleifend tellus. Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac, enim. Aliquam lorem ante, dapibus in, viverra quis, feugiat a.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="additional-information" class="section level1">
<h1>Additional Information</h1>
<div id="data-accessibility" class="section level2">
<h2>Data Accessibility</h2>
<p>The authors agree to share the raw data, digital study materials and analysis code. All study materials can be found on our OSF repository .</p>
</div>
<div id="author-contributions" class="section level2">
<h2>Author Contributions</h2>
<ul>
<li>Contributed to conception and design: TBA</li>
<li>Contributed to acquisition of data: TBA</li>
<li>Contributed to analysis and interpretation of data: TBA</li>
<li>Drafted and/or revised the article: TBA</li>
<li>Approved the submitted version for publication: TBA</li>
</ul>
</div>
<div id="conflict-of-interest" class="section level2">
<h2>Conflict of Interest</h2>
<p>Authors have no conflicts of interest to declare.</p>
</div>
<div id="funding" class="section level2">
<h2>Funding</h2>
<p>The proposed research is not funded. All necessary support is provided by the authors institutions. This study is an analysis of published research and does not require ethical approval.</p>
</div>
<div id="acknowledgments" class="section level2">
<h2>Acknowledgments</h2>
<p>We thank everybody.</p>
</div>
<div id="preregistration" class="section level2">
<h2>Preregistration</h2>
<p>Following Stage 1 in-principle acceptance, the authors agreed to pre-registration of the approved protocol on the Open Science Framework. The IPA registration can be found here: </p>
</div>
<div id="conflicts-of-interest" class="section level2">
<h2>Conflicts of Interest</h2>
<p>ARC, RT, and VRY currently serve as executive committee members for the Society of Transparency, Openness, and Replication in Kinesiology (STORK). VRY is a section editor and ARC is on the Steering Board for Registered Reports in Kinesiology. Neither will be involved in any aspect of handling this manuscript except as authors. The opinions or assertions contained herein are the private views of the author(s) and are not to be construed as official or reflecting the views of the Army or the Department of Defense. Any citations of commercial organizations and trade names in this report do not constitute an official Department of the Army endorsement of approval of the products or services of these organizations. No authors have any conflicts of interest to disclose. Approved for public release; distribution is unlimited.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>

<p>List of Names</p>
<div id="refs" class="references">
<div id="ref-Abt_Boreham_Davison_Jackson_Nevill_Wallace_Williams_2020">
<p>Abt, G., Boreham, C., Davison, G., Jackson, R., Nevill, A., Wallace, E., &amp; Williams, M. (2020). Power, precision, and sample size estimation in sport and exercise science research. <em>Journal of Sports Sciences</em>, <em>38</em>(17), 1933–1935. <a href="https://doi.org/10.1080/02640414.2020.1776002">https://doi.org/10.1080/02640414.2020.1776002</a></p>
</div>
<div id="ref-Boekel_Wagenmakers_Belay_Verhagen_Brown_Forstmann_2015">
<p>Boekel, W., Wagenmakers, E.-J., Belay, L., Verhagen, J., Brown, S., &amp; Forstmann, B. U. (2015). A purely confirmatory replication study of structural brain-behavior correlations. <em>Cortex</em>, <em>66</em>, 115–133. <a href="https://doi.org/10.1016/j.cortex.2014.11.019">https://doi.org/10.1016/j.cortex.2014.11.019</a></p>
</div>
<div id="ref-Borg_Bon_Sainani_Baguley_Tierney_Drovandi_2020">
<p>Borg, D. N., Bon, J. J., Sainani, K. L., Baguley, B. J., Tierney, N. J., &amp; Drovandi, C. (2020). Comment on: “Moving sport and exercise science forward: A call for the adoption of more transparent research practices”. <em>Sports Medicine</em>, <em>50</em>(8), 1551–1553. <a href="https://doi.org/10.1007/s40279-020-01298-5">https://doi.org/10.1007/s40279-020-01298-5</a></p>
</div>
<div id="ref-Borg_Lohse_Sainani_2020">
<p>Borg, D. N., Lohse, K. R., &amp; Sainani, K. L. (2020). Ten common statistical errors from all phases of research, and their fixes. <em>PM&amp;R</em>, <em>12</em>(6), 610–614. <a href="https://doi.org/10.1002/pmrj.12395">https://doi.org/10.1002/pmrj.12395</a></p>
</div>
<div id="ref-Burkner_2017">
<p>Bürkner, P.-C. (2017). Brms: An r package for bayesian multilevel models using stan. <em>Journal of Statistical Software</em>, <em>80</em>(1). <a href="https://doi.org/10.18637/jss.v080.i01">https://doi.org/10.18637/jss.v080.i01</a></p>
</div>
<div id="ref-buttner_are_2020">
<p>Büttner, F., Toomey, E., McClean, S., Roe, M., &amp; Delahunt, E. (2020). Are questionable research practices facilitating new discoveries in sport and exercise medicine? The proportion of supported hypotheses is implausibly high. <em>British Journal of Sports Medicine</em>. <a href="https://doi.org/10.1136/bjsports-2019-101863">https://doi.org/10.1136/bjsports-2019-101863</a></p>
</div>
<div id="ref-Caldwell_Vigotsky_2020">
<p>Caldwell, A. R., &amp; Vigotsky, A. D. (2020). <em>Does one effect size fit all? The case against default effect sizes for sport and exercise science</em>. SportRxiv. <a href="https://doi.org/10.31236/osf.io/tfx95">https://doi.org/10.31236/osf.io/tfx95</a></p>
</div>
<div id="ref-caldwell_moving_2020">
<p>Caldwell, A. R., Vigotsky, A. D., Tenan, M. S., Radel, R., Mellor, D. T., Kreutzer, A., Lahart, I. M., Mills, J. P., Boisgontier, M. P., Boardley, I., Bouza, B., Cheval, B., Chow, Z. R., Contreras, B., Dieter, B., Halperin, I., Haun, C., Knudson, D., Lahti, J., … Consortium for Transparency in Exercise Science (COTES) Collaborators. (2020). Moving sport and exercise science forward: A call for the adoption of more transparent research practices. <em>Sports Medicine</em>, <em>50</em>(3), 449–459. <a href="https://doi.org/10.1007/s40279-019-01227-1">https://doi.org/10.1007/s40279-019-01227-1</a></p>
</div>
<div id="ref-chambers_registered_2015">
<p>Chambers, C. D., Dienes, Z., McIntosh, R. D., Rotshtein, P., &amp; Willmes, K. (2015). Registered reports: Realigning incentives in scientific publishing. <em>Cortex</em>, <em>66</em>, A1–2. <a href="https://doi.org/10.1016/j.cortex.2015.03.022">https://doi.org/10.1016/j.cortex.2015.03.022</a></p>
</div>
<div id="ref-collaboration_estimating_2015">
<p>Collaboration, O. S. (2015). Estimating the reproducibility of psychological science. <em>Science</em>, <em>349</em>(6251). <a href="https://doi.org/10.1126/science.aac4716">https://doi.org/10.1126/science.aac4716</a></p>
</div>
<div id="ref-fanelli_how_2009">
<p>Fanelli, D. (2009). How many scientists fabricate and falsify research? A systematic review and meta-analysis of survey data. <em>PloS One</em>, <em>4</em>(5), e5738. <a href="https://doi.org/10.1371/journal.pone.0005738">https://doi.org/10.1371/journal.pone.0005738</a></p>
</div>
<div id="ref-fanelli_positive_2010">
<p>Fanelli, D. (2010). “Positive” results increase down the hierarchy of the sciences. <em>PLOS ONE</em>, <em>5</em>(4), e10068. <a href="https://doi.org/10.1371/journal.pone.0010068">https://doi.org/10.1371/journal.pone.0010068</a></p>
</div>
<div id="ref-head_extent_2015">
<p>Head, M. L., Holman, L., Lanfear, R., Kahn, A. T., &amp; Jennions, M. D. (2015). The extent and consequences of p-hacking in science. <em>PLOS Biology</em>, <em>13</em>(3), e1002106. <a href="https://doi.org/10.1371/journal.pbio.1002106">https://doi.org/10.1371/journal.pbio.1002106</a></p>
</div>
<div id="ref-John_Loewenstein_Prelec_2012">
<p>John, L. K., Loewenstein, G., &amp; Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth telling. <em>Psychological Science</em>, <em>23</em>(5), 524–532. <a href="https://doi.org/10.1177/0956797611430953">https://doi.org/10.1177/0956797611430953</a></p>
</div>
<div id="ref-Kharabian_Genon_2019">
<p>Kharabian Masouleh, S., Eickhoff, S. B., Hoffstaedter, F., &amp; Genon, S. (2019). Empirical examination of the replicability of associations between brain structure and psychological variables. <em>eLife</em>, <em>8</em>. <a href="https://doi.org/10.7554/elife.43464">https://doi.org/10.7554/elife.43464</a></p>
</div>
<div id="ref-munafo_manifesto_2017">
<p>Munafò, M. R., Nosek, B. A., Bishop, D. V. M., Button, K. S., Chambers, C. D., Percie du Sert, N., Simonsohn, U., Wagenmakers, E.-J., Ware, J. J., &amp; Ioannidis, J. P. A. (2017). A manifesto for reproducible science. <em>Nature Human Behaviour</em>, <em>1</em>(1), 1–9. <a href="https://doi.org/10.1038/s41562-016-0021">https://doi.org/10.1038/s41562-016-0021</a></p>
</div>
<div id="ref-Nosek_Errington_2017">
<p>Nosek, B. A., &amp; Errington, T. M. (2017). Making sense of replications. <em>eLife</em>, <em>6</em>. <a href="https://doi.org/10.7554/elife.23383">https://doi.org/10.7554/elife.23383</a></p>
</div>
<div id="ref-NosekErrington2019">
<p>Nosek, B. A., &amp; Errington, T. M. (2019). <em>What is replication?</em> Center for Open Science. <a href="https://doi.org/10.31222/osf.io/u4g6t">https://doi.org/10.31222/osf.io/u4g6t</a></p>
</div>
<div id="ref-Prinz_Schlange_Asadullah_2011">
<p>Prinz, F., Schlange, T., &amp; Asadullah, K. (2011). Believe it or not: How much can we rely on published data on potential drug targets? <em>Nature Reviews Drug Discovery</em>, <em>10</em>(9), 712–712. <a href="https://doi.org/10.1038/nrd3439-c1">https://doi.org/10.1038/nrd3439-c1</a></p>
</div>
<div id="ref-chanock_2007">
<p>Replicating genotype–phenotype associations. (2007). <em>Nature</em>, <em>447</em>(7145), 655–660. <a href="https://doi.org/10.1038/447655a">https://doi.org/10.1038/447655a</a></p>
</div>
<div id="ref-Sainani_2020">
<p>Sainani, K. L., Borg, D. N., Caldwell, A. R., Butson, M. L., Tenan, M. S., Vickers, A. J., Vigotsky, A. D., Warmenhoven, J., Nguyen, R., Lohse, K. R., &amp; al. (2020). Call to increase statistical collaboration in sports science, sport and exercise medicine and sports physiotherapy. <em>British Journal of Sports Medicine</em>, bjsports–2020–102607. <a href="https://doi.org/10.1136/bjsports-2020-102607">https://doi.org/10.1136/bjsports-2020-102607</a></p>
</div>
<div id="ref-Sainani_Lohse_Jones_Vickers_2019">
<p>Sainani, K. L., Lohse, K. R., Jones, P. R., &amp; Vickers, A. (2019). Magnitude‐based inference is not bayesian and is not a valid method of inference. <em>Scandinavian Journal of Medicine &amp; Science in Sports</em>, <em>29</em>(9), 1428–1436. <a href="https://doi.org/10.1111/sms.13491">https://doi.org/10.1111/sms.13491</a></p>
</div>
<div id="ref-scheel_excess_2020">
<p>Scheel, A. M., Schijen, M., &amp; Lakens, D. (2020). An excess of positive results: Comparing the standard psychology literature with registered reports. <em>PsyArXiv</em>. <a href="https://doi.org/10.31234/osf.io/p6e9c">https://doi.org/10.31234/osf.io/p6e9c</a></p>
</div>
<div id="ref-simmons_false-positive_2011">
<p>Simmons, J. P., Nelson, L. D., &amp; Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. <em>Psychological Science</em>, <em>22</em>(11), 1359–1366. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a></p>
</div>
<div id="ref-Tamminen_Poucher_2018">
<p>Tamminen, K. A., &amp; Poucher, Z. A. (2018). Open science in sport and exercise psychology: Review of current approaches and considerations for qualitative inquiry. <em>Psychology of Sport and Exercise</em>, <em>36</em>, 17–28. <a href="https://doi.org/10.1016/j.psychsport.2017.12.010">https://doi.org/10.1016/j.psychsport.2017.12.010</a></p>
</div>
<div id="ref-Turner_Paul_Miller_Barbey_2018">
<p>Turner, B. O., Paul, E. J., Miller, M. B., &amp; Barbey, A. K. (2018). Small sample sizes reduce the replicability of task-based fMRI studies. <em>Communications Biology</em>, <em>1</em>(1). <a href="https://doi.org/10.1038/s42003-018-0073-z">https://doi.org/10.1038/s42003-018-0073-z</a></p>
</div>
</div>
</div>


<br /><br /><br /><br />
<p class="caption">Communications in Kinesiology</p>

</div>     
  <script>
    (function () {
	var script = document.createElement("script");
	script.type = "text/javascript";
	script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
	document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>
</body>


</html> 
